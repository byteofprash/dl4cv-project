{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from src.extractor_utils import (predict, save_prediction)\n",
    "from src.Dataset import KaggleSafeDriverDataset\n",
    "from src.imgnet_utils import denormalize\n",
    "from src.data_loader import _create_dataLoader\n",
    "from src.data_loader import _create_dataLoader\n",
    "from src.convnet_models import (MyResNet, MyInception, MyDenseNet,MyVgg16Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing resources to extrac the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU's available:\n",
      "\n",
      "cpu_count: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"{} GPU's available:\".format(torch.cuda.device_count()) )\n",
    "cpu_count = torch.multiprocessing.cpu_count()\n",
    "print(\"\\ncpu_count: {}\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only one GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "use_DataParalel= False\n",
    "use_CPU= False        \n",
    "\n",
    "if use_gpu:\n",
    "    if use_DataParalel: \n",
    "        print(\"Using DataParalel in all {} GPUS\".format(torch.cuda.device_count()))\n",
    "\n",
    "    else:\n",
    "        print('Using only one GPU')\n",
    "\n",
    "if use_CPU:         # http://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html \n",
    "    print(\"Using {} CPU's\".format(cpu_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2train = \"/home/Prashanth/dl4cv-project/data/train\" \n",
    "path2test = \"/home/Prashanth/dl4cv-project/data/test\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Prashanth/anaconda3/lib/python3.5/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img_width = img_height=224 #to use InceptionV3 it must img_width and img_height be changed to 300\n",
    "\n",
    "# Data augmentation and normalization for training \n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Scale((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]),\n",
    "}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "use_only = 1.0 # Use only is the percentage of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsets = {\n",
    "    'train': KaggleSafeDriverDataset(path2train, transforms=data_transforms['train'],use_only=use_only),\n",
    "    'valid': KaggleSafeDriverDataset(path2train, transforms=data_transforms['valid'],use_only=use_only, is_val=True, val_size=0.2),\n",
    "    'test':  KaggleSafeDriverDataset(path2test, transforms=data_transforms['valid'],use_only=use_only, is_test=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset_loaders = _create_dataLoader(dsets, batch_size, pin_memory=False, use_shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17940, {'test': 79726, 'train': 17940, 'valid': 4484})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['train','valid', 'test']} \n",
    "dset_classes = len(dsets['train'].y)\n",
    "dset_classes, dset_sizes\n",
    "\n",
    "# Dataset have much more samples than datatrain ***It comes from the test.zip****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            29G        2.4G         16G         12M         10G         26G\n",
      "Swap:            0B          0B          0B\n",
      "Sat Feb  3 23:02:29 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.12                 Driver Version: 390.12                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P0    71W / 149W |    848MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1943      G   /usr/lib/xorg/Xorg                            15MiB |\n",
      "|    0      4826      C   /home/Prashanth/anaconda3/bin/python         802MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    !free -h\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using VGG16 model\n",
      "MyVgg16Net(\n",
      "  (mrnc): MyVggConv(\n",
      "    (model): VGG(\n",
      "      (features): Sequential(\n",
      "        (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU(inplace)\n",
      "        (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (5): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (6): ReLU(inplace)\n",
      "        (7): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): ReLU(inplace)\n",
      "        (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (10): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): ReLU(inplace)\n",
      "        (12): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (13): ReLU(inplace)\n",
      "        (14): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): ReLU(inplace)\n",
      "        (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (17): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): ReLU(inplace)\n",
      "        (19): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (20): ReLU(inplace)\n",
      "        (21): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (22): ReLU(inplace)\n",
      "        (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (24): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (25): ReLU(inplace)\n",
      "        (26): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (27): ReLU(inplace)\n",
      "        (28): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (29): ReLU(inplace)\n",
      "        (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "      (classifier): Sequential(\n",
      "        (0): Linear(in_features=25088, out_features=4096)\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Dropout(p=0.5)\n",
      "        (3): Linear(in_features=4096, out_features=4096)\n",
      "        (4): ReLU(inplace)\n",
      "        (5): Dropout(p=0.5)\n",
      "        (6): Linear(in_features=4096, out_features=1000)\n",
      "      )\n",
      "    )\n",
      "    (features): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace)\n",
      "        (2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): ReLU(inplace)\n",
      "        (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (5): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (6): ReLU(inplace)\n",
      "        (7): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (8): ReLU(inplace)\n",
      "        (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (10): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (11): ReLU(inplace)\n",
      "        (12): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (13): ReLU(inplace)\n",
      "        (14): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (15): ReLU(inplace)\n",
      "        (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (17): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (18): ReLU(inplace)\n",
      "        (19): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (20): ReLU(inplace)\n",
      "        (21): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (22): ReLU(inplace)\n",
      "        (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "        (24): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (25): ReLU(inplace)\n",
      "        (26): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (27): ReLU(inplace)\n",
      "        (28): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (29): ReLU(inplace)\n",
      "        (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mrnd): MyVggDens(\n",
      "    (dens1): Linear(in_features=4096, out_features=512)\n",
      "    (dens2): Linear(in_features=512, out_features=128)\n",
      "    (dens3): Linear(in_features=128, out_features=10)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "use_resnet = False\n",
    "use_inception = False\n",
    "use_denseNet = False\n",
    "use_vgg16 = True\n",
    "\n",
    "if use_resnet:\n",
    "    print('Using ResNet model')\n",
    "    model_name = \"ResNet\"\n",
    "#    model = MyResNet()\n",
    "    model = models.resnet18()\n",
    "elif use_inception:\n",
    "    print('Using Inception model')\n",
    "    model_name = \"Inception\"\n",
    "    model = MyInception()\n",
    "elif use_denseNet:\n",
    "    print('Using DenseNet model')\n",
    "    model_name = \"DenseNet\"    \n",
    "    model = MyDenseNet()\n",
    "elif use_vgg16:\n",
    "    print('Using VGG16 model')\n",
    "    model_name = \"vgg16\"    \n",
    "    model = MyVgg16Net()\n",
    "    print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    if use_DataParalel:\n",
    "        print(\"Using all GPU's \")\n",
    "        model = torch.nn.DataParallel(model) #device_ids=[1,3]\n",
    "        model.cuda()\n",
    "        convnet = model.module.mrnc\n",
    "    else:\n",
    "        print('Using GPU')# {}'.format(device_id))\n",
    "        model.cuda()\n",
    "        convnet = model.mrnc \n",
    "\n",
    "if use_CPU:\n",
    "    print(\"Using CPU's\")\n",
    "    convnet = model.mrnc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 560/560 ok\n",
      "Execution time 253.00 s\n",
      "predict: 140/140 ok\n",
      "Execution time 63.00 s\n",
      "predict: 2491/2491 ok\n",
      "Execution time 1120.00 s\n"
     ]
    }
   ],
   "source": [
    "#extract features from images\n",
    "convOutput_train = predict(dset_loaders['train'], convnet,use_gpu=use_gpu)\n",
    "convOutput_valid = predict(dset_loaders['valid'], convnet,use_gpu=use_gpu)\n",
    "convOutput_test = predict(dset_loaders['test'], convnet,use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17940]) torch.Size([17940, 1000])\n",
      "torch.Size([4484]) torch.Size([4484, 1000])\n",
      "torch.Size([79726]) torch.Size([79726, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(convOutput_train['true'].size(), convOutput_train['pred'].size())\n",
    "print(convOutput_valid['true'].size(), convOutput_valid['pred'].size())\n",
    "print(convOutput_test['true'].size(), convOutput_test['pred'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.LongTensor torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(convOutput_train['true'].type(), convOutput_train['pred'].type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sav_feats= {\n",
    "    'train': (convOutput_train['pred'], convOutput_train['true'],model_name),\n",
    "    'valid': (convOutput_valid['pred'], convOutput_valid['true'],model_name),\n",
    "    'test': (convOutput_test['pred'], convOutput_test['true'],model_name)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vgg16'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sav_feats['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2features = './features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving vgg16 valid\n",
      "Saved in:./features/valid/vgg16.npz\n",
      "\n",
      "Saving vgg16 train\n",
      "Saved in:./features/train/vgg16.npz\n",
      "\n",
      "Saving vgg16 test\n",
      "Saved in:./features/test/vgg16.npz\n"
     ]
    }
   ],
   "source": [
    "save_prediction(path2features,sav_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
